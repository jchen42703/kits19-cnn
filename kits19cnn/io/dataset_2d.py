import os
from os.path import join
from pathlib import Path
from glob import glob
import numpy as np

import torch
from torch.utils.data import Dataset

class SliceDataset(Dataset):
    def __init__(self, im_ids: np.array, pos_slice_dict: dict, transforms=None,
                 preprocessing=None, p_pos_per_sample: float = 0.33,
                 mode: str = "segmentation", num_classes: int = 3):
        """
        Reads from a directory of 2D slice numpy arrays and samples positive
        slices. Assumes the data directory contains 2D slices processed by
        `io.Preprocessor.save_dir_as_2d()`.
        Attributes
            im_ids (np.ndarray): of image names.
            pos_slice_dict (dict): dictionary generated by
                `io.Preprocessor.save_dir_as_2d()`
            transforms (albumentations.augmentation): transforms to apply
                before preprocessing. Defaults to HFlip and ToTensor
            preprocessing: ops to perform after transforms, such as
                z-score standardization. Defaults to None.
            p_pos_per_sample (float): probability at which to sample slices
                that contain foreground classes.
            mode (str): one of ["seg", "clf", "both"]
            num_classes (int): number of classes. 3 for this challenge.
        """
        self.im_ids = im_ids
        self.pos_slice_dict = pos_slice_dict
        self.transforms = transforms
        self.preprocessing = preprocessing
        self.p_pos_per_sample = p_pos_per_sample
        print(f"Assuming inputs are .npy files...")
        self.check_fg_idx_per_class()
        assert mode in ["segmentation", "classification", "both"], \
            "mode must be one of ['segmentation', 'classification', 'both']"
        self.mode = mode
        self.num_classes = num_classes

    def __getitem__(self, idx):
        # loads data as a numpy arr and then adds the channel + batch size dimensions
        case_id = self.im_ids[idx]
        x, y = self.load_slices(case_id)

        if self.transforms:
            x = x[None] if len(x.shape) == 3 else x
            y = y[None] if len(y.shape) == 3 else y
            # batchgenerators requires shape: (b, c, ...)
            data_dict = self.transforms(**{"data": x, "seg": y})
            x, y = data_dict["data"], data_dict["seg"]

        if self.mode in ["both", "clf_only"]:
            y_clf = torch.from_numpy(self.get_clf_label_from_mask(y))

        if self.preprocessing:
            preprocessed = self.preprocessing(**{"data": x, "seg": y})
            x, y = preprocessed["data"], preprocessed["seg"]
        # squeeze to remove batch size dim
        x = torch.squeeze(x, dim=0).float()
        y = torch.squeeze(y, dim=0)

        if self.mode == "both":
            return {"features": x, "seg_targets": y, "clf_targets": y_clf}
        elif self.mode == "classification":
            return (x, y_clf)
        elif self.mode == "segmentation":
            return (x, y)

    def __len__(self):
        return len(self.im_ids)

    def load_slices(self, case_fpath):
        """
        Gets the slice idx using self.get_slice_idx_str() and actually loads
        the appropriate slice array.
        """
        slice_idx_str = self.get_slice_idx_str(case_fpath)
        x_path = join(case_fpath, f"imaging_{slice_idx_str}.npy")
        y_path = join(case_fpath, f"segmentation_{slice_idx_str}.npy")
        return (np.load(x_path)[None], np.load(y_path)[None])

    def get_slice_idx_str(self, case_fpath):
        """
        Gets the slice idx and processes it so that it fits how the arrays
        were saved by `io.Preprocessor.save_dir_as_2d`.
        """
        # extracting slice:
        temp_p = np.random.uniform(0, 1)
        if temp_p < self.p_pos_per_sample:
            slice_idx = self.get_rand_pos_slice_idx(case_fpath)
        else:
            slice_idx = self.get_rand_slice_idx(case_fpath)
        slice_idx_str = self._parse_slice_idx_to_str(slice_idx)
        return slice_idx_str

    def get_rand_pos_slice_idx(self, case_fpath):
        """
        Gets a random positive slice index from self.pos_slice_dict (that was
        generated by io.preprocess.Preprocessor when save_as_slices=True).
        Args:
            case_fpath: each element of self.im_ids (path to a case folder)
        Returns:
            an integer representing a random non-background class slice index
        """
        case_raw = Path(case_fpath).name
        # finding random positive class index
        if self.fg_idx_per_class:
            sampled_class = np.random.choice(self.fg_classes)
            slice_indices = self.pos_slice_dict[case_raw][sampled_class]
            random_pos_coord = np.random.choice(slice_indices)
        else:
            random_pos_coord = np.random.choice(self.pos_slice_dict[case_raw])
        return random_pos_coord

    def get_rand_slice_idx(self, case_fpath):
        """
        Args:
            case_fpath: each element of self.im_ids (path to a case folder)
        Returns:
            A randomly selected slice index
        """
        # assumes that there are no other files in said directory with "imaging_"
        _slice_files = [file for file in os.listdir(case_fpath)
                        if file.startswith("imaging_")]
        return np.random.randint(0, len(_slice_files))

    def check_fg_idx_per_class(self):
        """
        checks the first key: value pair of self.pos_slice_dict
        If dict -> fg_idx_per_class, if list: not fg_idx_per_class
        fg_idx_per_class -> uniformly sample per class v. sample all fg idx
        """
        dummy_key = list(self.pos_slice_dict.keys())[0]
        dummy_value = self.pos_slice_dict[dummy_key]
        self.fg_idx_per_class = True if isinstance(dummy_value, dict) else False
        if self.fg_idx_per_class:
            self.fg_classes = list(dummy_value.keys())

    def get_clf_label_from_mask(self, mask: np.array):
        """
        Multi-label one-hot encoding of mask to get the classification
        label.
        Args:
            mask (np.ndarray): contains int in [0, num_classes-1]
        Returns:
            one_hot (np.ndarray): multi-label one hot encoded array
                i.e. [0, 1, 0] or [1, 0, 1], etc.
        """
        unique = np.unique(mask).astype(np.int32)
        one_hot = np.zeros(self.num_classes)
        one_hot[unique] = 1
        return one_hot

    def _parse_slice_idx_to_str(self, slice_idx):
        """
        Parse the slice index to a three digit string for reading the 2D .npy
        files generated by io.preprocess.Preprocessor.
        """
        slice_idx_str = str(slice_idx)
        while len(slice_idx_str) < 3:
            slice_idx_str = "0"+slice_idx_str
        return slice_idx_str

class PseudoSliceDataset(SliceDataset):
    def __init__(self, im_ids: np.array, pos_slice_dict: dict, transforms=None,
                 preprocessing=None, p_pos_per_sample: float = 0.33,
                 mode: str = "segmentation", num_classes: int = 3,
                 num_pseudo_slices=num_pseudo_slices):
        """
        Reads from a directory of 2D slice numpy arrays and samples positive
        slices. Assumes the data directory contains 2D slices processed by
        `io.Preprocessor.save_dir_as_2d()`.
        Attributes
            im_ids (np.ndarray): of image names.
            pos_slice_dict (dict): dictionary generated by
                `io.Preprocessor.save_dir_as_2d()`
            transforms (albumentations.augmentation): transforms to apply
                before preprocessing. Defaults to HFlip and ToTensor
            preprocessing: ops to perform after transforms, such as
                z-score standardization. Defaults to None.
            p_pos_per_sample (float): probability at which to sample slices
                that contain foreground classes.
            mode (str): one of ["seg", "clf", "both"]
            num_classes (int): number of classes. 3 for this challenge.
            num_pseudo_slices (int): number of pseudo 3D slices. Defaults to 1.
                1 meaning no pseudo slices. If it's greater than 1, it must
                be odd (even numbers above and below)
        """
        super().__init__(im_ids=im_ids, pos_slice_dict=pos_slice_dict,
                         transforms=transforms, preprocessing=preprocessing,
                         p_pos_per_sample=p_pos_per_sample, mode=mode,
                         num_classes=num_classes)
        self.num_pseudo_slices = num_pseudo_slices
        assert num_pseudo_slices % 2 == 1, \
            "`num_pseudo_slices` must be odd. i.e. 7 -> 3 above and 3 below"

    def load_slices(self, case_fpath):
        """
        Gets the slice idx using self.get_slice_idx_str() and actually loads
        the appropriate slice array. Returned arrays have shape:
            (batch_size, n_channels, h, w)
        for batchgenerators transforms.
        """
        center_slice_idx_str, center_slice_idx = self.get_slice_idx_str(case_fpath)
        total_num_slices = len(glob(join(case_fpath, "imaging_*.npy")))
        min = center_slice_idx - (self.num_pseudo_slices - 1) // 2
        max = center_slice_idx + (self.num_pseudo_slices - 1) // 2 + 1

        x_path = join(case_fpath, f"imaging_{center_slice_idx_str}.npy")
        y_path = join(case_fpath, f"segmentation_{center_slice_idx_str}.npy")
        center_x, center_y = np.load(x_path)[None], np.load(y_path)[None]

        if self.num_pseudo_slices == 1:
            return (center_x, center_y)
        elif self.num_pseudo_slices > 1:
            # total shape: (1, num_pseudo_slices, h, w)
            x_arr = np.zeros((1, self.num_pseudo_slices) + center_x.shape[2:])
            for idx, slice_idx in enumerate(range(min, max)):
                slice_idx_str = self._parse_slice_idx_to_str(slice_idx)
                x_path = join(case_fpath, f"imaging_{slice_idx_str}.npy")
                # loading slices if they exist
                if os.path.isfile(x_path):
                    x_arr[:, idx] = np.load(x_path)
            return (x_arr, center_y)

    def get_slice_idx_str(self, case_fpath):
        """
        Gets the slice idx and processes it so that it fits how the arrays
        were saved by `io.Preprocessor.save_dir_as_2d`.
        """
        # extracting slice:
        temp_p = np.random.uniform(0, 1)
        if temp_p < self.p_pos_per_sample:
            slice_idx = self.get_rand_pos_slice_idx(case_fpath)
        else:
            slice_idx = self.get_rand_slice_idx(case_fpath)
        slice_idx_str = self._parse_slice_idx_to_str(slice_idx)
        return (slice_idx_str, slice_idx)
